{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0ERkCmSSG-I"
      },
      "source": [
        "# Install Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jRh9rJEK2Eb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: yfinance in ./.venv/lib/python3.11/site-packages (0.2.50)\n",
            "Requirement already satisfied: langchain_pinecone in ./.venv/lib/python3.11/site-packages (0.2.0)\n",
            "Requirement already satisfied: openai in ./.venv/lib/python3.11/site-packages (1.56.1)\n",
            "Requirement already satisfied: python-dotenv in ./.venv/lib/python3.11/site-packages (1.0.1)\n",
            "Requirement already satisfied: langchain-community in ./.venv/lib/python3.11/site-packages (0.3.9)\n",
            "Requirement already satisfied: sentence_transformers in ./.venv/lib/python3.11/site-packages (3.3.1)\n",
            "Requirement already satisfied: pandas>=1.3.0 in ./.venv/lib/python3.11/site-packages (from yfinance) (2.2.3)\n",
            "Requirement already satisfied: numpy>=1.16.5 in ./.venv/lib/python3.11/site-packages (from yfinance) (1.26.4)\n",
            "Requirement already satisfied: requests>=2.31 in ./.venv/lib/python3.11/site-packages (from yfinance) (2.32.3)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in ./.venv/lib/python3.11/site-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: lxml>=4.9.1 in ./.venv/lib/python3.11/site-packages (from yfinance) (5.3.0)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in ./.venv/lib/python3.11/site-packages (from yfinance) (4.3.6)\n",
            "Requirement already satisfied: pytz>=2022.5 in ./.venv/lib/python3.11/site-packages (from yfinance) (2024.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in ./.venv/lib/python3.11/site-packages (from yfinance) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in ./.venv/lib/python3.11/site-packages (from yfinance) (3.17.8)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in ./.venv/lib/python3.11/site-packages (from yfinance) (4.12.3)\n",
            "Requirement already satisfied: html5lib>=1.1 in ./.venv/lib/python3.11/site-packages (from yfinance) (1.1)\n",
            "Requirement already satisfied: aiohttp<3.10,>=3.9.5 in ./.venv/lib/python3.11/site-packages (from langchain_pinecone) (3.9.5)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.3 in ./.venv/lib/python3.11/site-packages (from langchain_pinecone) (0.3.21)\n",
            "Requirement already satisfied: pinecone-client<6.0.0,>=5.0.0 in ./.venv/lib/python3.11/site-packages (from langchain_pinecone) (5.0.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.11/site-packages (from openai) (4.6.2.post1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.11/site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.11/site-packages (from openai) (0.28.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in ./.venv/lib/python3.11/site-packages (from openai) (0.8.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in ./.venv/lib/python3.11/site-packages (from openai) (2.10.3)\n",
            "Requirement already satisfied: sniffio in ./.venv/lib/python3.11/site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in ./.venv/lib/python3.11/site-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in ./.venv/lib/python3.11/site-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: PyYAML>=5.3 in ./.venv/lib/python3.11/site-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./.venv/lib/python3.11/site-packages (from langchain-community) (2.0.36)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in ./.venv/lib/python3.11/site-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in ./.venv/lib/python3.11/site-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.8 in ./.venv/lib/python3.11/site-packages (from langchain-community) (0.3.9)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in ./.venv/lib/python3.11/site-packages (from langchain-community) (0.1.147)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in ./.venv/lib/python3.11/site-packages (from langchain-community) (2.6.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in ./.venv/lib/python3.11/site-packages (from langchain-community) (9.0.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in ./.venv/lib/python3.11/site-packages (from sentence_transformers) (4.46.3)\n",
            "Requirement already satisfied: torch>=1.11.0 in ./.venv/lib/python3.11/site-packages (from sentence_transformers) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.11/site-packages (from sentence_transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in ./.venv/lib/python3.11/site-packages (from sentence_transformers) (1.14.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in ./.venv/lib/python3.11/site-packages (from sentence_transformers) (0.26.3)\n",
            "Requirement already satisfied: Pillow in ./.venv/lib/python3.11/site-packages (from sentence_transformers) (11.0.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.11/site-packages (from aiohttp<3.10,>=3.9.5->langchain_pinecone) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.11/site-packages (from aiohttp<3.10,>=3.9.5->langchain_pinecone) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.11/site-packages (from aiohttp<3.10,>=3.9.5->langchain_pinecone) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.11/site-packages (from aiohttp<3.10,>=3.9.5->langchain_pinecone) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in ./.venv/lib/python3.11/site-packages (from aiohttp<3.10,>=3.9.5->langchain_pinecone) (1.18.3)\n",
            "Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: soupsieve>1.2 in ./.venv/lib/python3.11/site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.6)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.venv/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.23.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./.venv/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: six>=1.9 in ./.venv/lib/python3.11/site-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
            "Requirement already satisfied: webencodings in ./.venv/lib/python3.11/site-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
            "Requirement already satisfied: certifi in ./.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: filelock in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (24.2)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in ./.venv/lib/python3.11/site-packages (from langchain<0.4.0,>=0.3.8->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.venv/lib/python3.11/site-packages (from langchain-core<0.4,>=0.3->langchain_pinecone) (1.33)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.venv/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./.venv/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.11/site-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.11/site-packages (from pandas>=1.3.0->yfinance) (2024.2)\n",
            "Requirement already satisfied: pinecone-plugin-inference<2.0.0,>=1.0.3 in ./.venv/lib/python3.11/site-packages (from pinecone-client<6.0.0,>=5.0.0->langchain_pinecone) (1.1.0)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in ./.venv/lib/python3.11/site-packages (from pinecone-client<6.0.0,>=5.0.0->langchain_pinecone) (0.0.7)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in ./.venv/lib/python3.11/site-packages (from pinecone-client<6.0.0,>=5.0.0->langchain_pinecone) (2.2.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests>=2.31->yfinance) (3.4.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in ./.venv/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: sympy in ./.venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in ./.venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in ./.venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in ./.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in ./.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.4.5)\n",
            "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3->langchain_pinecone) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.venv/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.11/site-packages (from yarl<2.0,>=1.0->aiohttp<3.10,>=3.9.5->langchain_pinecone) (0.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.11/site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "! pip install yfinance langchain_pinecone openai python-dotenv langchain-community sentence_transformers python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gskZos1j1eeV"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/brauliopf/Documents/Dev/headstarter/projects/wk7/.venv/lib/python3.11/site-packages/pinecone/data/index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from tqdm.autonotebook import tqdm\n"
          ]
        }
      ],
      "source": [
        "from langchain_pinecone import PineconeVectorStore\n",
        "from openai import OpenAI\n",
        "import json\n",
        "import yfinance as yf\n",
        "import concurrent.futures\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.schema import Document\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from pinecone import Pinecone\n",
        "import numpy as np\n",
        "import requests\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "import signal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Set up global functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a timeout handler\n",
        "def timeout_handler(signum, frame):\n",
        "    raise TimeoutError(\"Execution timed out\")\n",
        "\n",
        "# Set the signal handler\n",
        "signal.signal(signal.SIGALRM, timeout_handler)\n",
        "\n",
        "# Initialize Pinecone\n",
        "pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"),)\n",
        "\n",
        "# Connect to your Pinecone index\n",
        "pc_index = pc.Index(\"stocks\")\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv(override=True);\n",
        "\n",
        "# Initialize tracking lists\n",
        "successful_tickers = []\n",
        "unsuccessful_tickers = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "X1Gg34Y-2A8_"
      },
      "outputs": [],
      "source": [
        "def get_stock_info(symbol: str) -> dict:\n",
        "    \"\"\"\n",
        "    Retrieves and formats detailed information about a stock from Yahoo Finance (yf).\n",
        "\n",
        "    Args:\n",
        "        symbol (str): The stock ticker symbol to look up.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing detailed stock information, including ticker, name,\n",
        "              business summary, city, state, country, industry, and sector.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        signal.alarm(7)\n",
        "        data = yf.Ticker(symbol)\n",
        "        signal.alarm(0)\n",
        "        stock_info = data.info\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching stock info for {symbol}: {e}\")\n",
        "        return None\n",
        "\n",
        "    properties = {\n",
        "        \"Ticker\": stock_info.get('symbol', 'Information not available'),\n",
        "        'Name': stock_info.get('longName', 'Information not available'),\n",
        "        'Business Summary': stock_info.get('longBusinessSummary'),\n",
        "        'City': stock_info.get('city', 'Information not available'),\n",
        "        'State': stock_info.get('state', 'Information not available'),\n",
        "        'Country': stock_info.get('country', 'Information not available'),\n",
        "        'Industry': stock_info.get('industry', 'Information not available'),\n",
        "        'Sector': stock_info.get('sector', 'Information not available'),\n",
        "        '10-Day AVG Volume': stock_info.get('averageDailyVolume10Day', 'Information not available'),\n",
        "        'Market Cap': stock_info.get('marketCap', 'Information not available'),\n",
        "    }\n",
        "\n",
        "    return properties"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zk1P2UGDLqsz",
        "outputId": "82d107e2-be29-4c9c-89a5-8d4ab11a8e9c"
      },
      "outputs": [],
      "source": [
        "def get_huggingface_embeddings(text, model_name=\"sentence-transformers/all-mpnet-base-v2\"):\n",
        "    \"\"\"\n",
        "    Generates embeddings for the given text using a specified Hugging Face model.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input text to generate embeddings for.\n",
        "        model_name (str): The name of the Hugging Face model to use.\n",
        "                          Defaults to \"sentence-transformers/all-mpnet-base-v2\".\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: The generated embeddings as a NumPy array.\n",
        "    \"\"\"\n",
        "    model = SentenceTransformer(model_name)\n",
        "    return model.encode(text)\n",
        "\n",
        "\n",
        "def cosine_similarity_between_sentences(sentence1, sentence2):\n",
        "    \"\"\"\n",
        "    Calculates the cosine similarity between two sentences.\n",
        "\n",
        "    Args:\n",
        "        sentence1 (str): The first sentence for similarity comparison.\n",
        "        sentence2 (str): The second sentence for similarity comparison.\n",
        "\n",
        "    Returns:\n",
        "        float: The cosine similarity score between the two sentences,\n",
        "               ranging from -1 (completely opposite) to 1 (identical).\n",
        "\n",
        "    Notes:\n",
        "        Prints the similarity score to the console in a formatted string.\n",
        "    \"\"\"\n",
        "    # Get embeddings for both sentences\n",
        "    embedding1 = np.array(get_huggingface_embeddings(sentence1))\n",
        "    embedding2 = np.array(get_huggingface_embeddings(sentence2))\n",
        "\n",
        "    # Reshape embeddings for cosine_similarity function\n",
        "    # Convert 1D array to 2D array (1 rows x {length of array} columns)\n",
        "    # \"-1\" sets the number of columns based on the original array length. \n",
        "    embedding1 = embedding1.reshape(1, -1)\n",
        "    embedding2 = embedding2.reshape(1, -1)\n",
        "\n",
        "    # Calculate cosine similarity\n",
        "    similarity = cosine_similarity(embedding1, embedding2)\n",
        "    similarity_score = similarity[0][0]\n",
        "    print(f\"Cosine similarity between the two sentences: {similarity_score:.4f}\")\n",
        "    return similarity_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGptiJJM23Yn",
        "outputId": "6f2baa5f-b7e2-461b-ced2-1be8ec19bee5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cosine similarity between the two sentences: 0.3635\n"
          ]
        }
      ],
      "source": [
        "# Test similarity score\n",
        "aapl_info = get_stock_info(\"AAPL\")\n",
        "\n",
        "aapl_description = aapl_info['Business Summary']\n",
        "\n",
        "company_description = \"I want to find companies that make smartphones and are headquarted in California\"\n",
        "\n",
        "similarity = cosine_similarity_between_sentences(aapl_description, company_description)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create Vector Index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OoPZQWyRufp"
      },
      "source": [
        "## Get all the Stocks in the Stock Market"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfm8BFeuRs4Z",
        "outputId": "f7b6531a-4fbf-4c76-cc87-303679327931"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File downloaded successfully and saved as 'company_tickers.json'\n"
          ]
        }
      ],
      "source": [
        "def get_company_tickers():\n",
        "    \"\"\"\n",
        "    Downloads and parses the Stock ticker symbols from the GitHub-hosted SEC company tickers JSON file.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing company tickers and related information.\n",
        "\n",
        "    Notes:\n",
        "        The data is sourced from the official SEC website via a GitHub repository:\n",
        "        https://raw.githubusercontent.com/team-headstart/Financial-Analysis-and-Automation-with-LLMs/main/company_tickers.json\n",
        "    \"\"\"\n",
        "    # URL to fetch the raw JSON file from GitHub\n",
        "    url = \"https://raw.githubusercontent.com/team-headstart/Financial-Analysis-and-Automation-with-LLMs/main/company_tickers.json\"\n",
        "\n",
        "    # Making a GET request to the URL\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # Checking if the request was successful\n",
        "    if response.status_code == 200:\n",
        "        # Parse the JSON content directly\n",
        "        # decode as utf-8 (Unicode --Standard)\n",
        "        company_tickers = json.loads(response.content.decode('utf-8'))\n",
        "\n",
        "        # Optionally save the content to a local file for future use\n",
        "        with open(\"company_tickers.json\", \"w\", encoding=\"utf-8\") as file:\n",
        "            json.dump(company_tickers, file, indent=4)\n",
        "\n",
        "        print(\"File downloaded successfully and saved as 'company_tickers.json'\")\n",
        "        return company_tickers\n",
        "    else:\n",
        "        print(f\"Failed to download file. Status code: {response.status_code}\")\n",
        "        return None\n",
        "\n",
        "company_tickers = get_company_tickers()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2g0tXXISQz-",
        "outputId": "4a9f71a8-2017-470c-df7f-53b0a17675e0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "9998"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(company_tickers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCPYOo32VhOr"
      },
      "source": [
        "## Inserting Stocks into Pinecone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uYmYnT6SQ9N",
        "outputId": "c45789c5-a025-4e1a-8dfd-72a6ce31f586"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/7l/scl9qg_x7h96pccwh3xspr3w0000gn/T/ipykernel_1858/3414157537.py:6: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  hf_embeddings = HuggingFaceEmbeddings() # use as parameter only. if you want to execute, use $get_huggingface_embeddings()\n",
            "/var/folders/7l/scl9qg_x7h96pccwh3xspr3w0000gn/T/ipykernel_1858/3414157537.py:6: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
            "  hf_embeddings = HuggingFaceEmbeddings() # use as parameter only. if you want to execute, use $get_huggingface_embeddings()\n"
          ]
        }
      ],
      "source": [
        "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
        "\n",
        "index_name = \"stocks\"\n",
        "namespace = \"stock-descriptions-rich\"\n",
        "\n",
        "hf_embeddings = HuggingFaceEmbeddings() # use as parameter only. if you want to execute, use $get_huggingface_embeddings()\n",
        "vectorstore = PineconeVectorStore(index_name=index_name, embedding=hf_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PROCESS FEW AT A TIME\n",
        "# pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
        "\n",
        "# index = pc.Index(index_name)\n",
        "\n",
        "# # Delete all the stocks in the Pinecone index \"stock-descriptions\"\n",
        "# # index.delete(delete_all=True, namespace=namespace)\n",
        "\n",
        "# company_tickers = load_test_tickers()\n",
        "\n",
        "# # Prepare your tickers: remove already processed + remove duplicates\n",
        "# tickers_to_process = list(set([company_tickers[num]['ticker'] for num in company_tickers.keys() if company_tickers[num]['ticker'] not in successful_tickers]))\n",
        "\n",
        "# # Process them\n",
        "# print(f'{len(tickers_to_process)}:', tickers_to_process)\n",
        "\n",
        "# # generate embeddings for one stock\n",
        "# stock_ticker = tickers_to_process[3]\n",
        "# stock_data = get_stock_info(stock_ticker)\n",
        "# stock_description = stock_data['Business Summary']\n",
        "# stock_embedding = get_huggingface_embeddings(stock_description)\n",
        "\n",
        "# # insert the stock embedding into the Pinecone index\n",
        "# stock_embedding_list = stock_embedding.tolist() if isinstance(stock_embedding, np.ndarray) else stock_embedding\n",
        "\n",
        "# index.upsert(vectors=[\n",
        "#   {\"id\":str(stock_data[\"Ticker\"]), \"values\":stock_embedding_list, \"metadata\":stock_data}\n",
        "#   ], namespace=namespace)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List all vectors in the index (CAREFUL: too much data!)\n",
        "# for ids in index.list(prefix='', limit=10, namespace=namespace):\n",
        "#     print(ids) # ['pref1', 'pref2', 'pref3']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Sequential Process Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![](https://mermaid.ink/img/pako:eNqNkl1rgzAUhv9KyMXYwF74cSVjYA0rhY6WKRQWe5FqWqU1cUm8GKX_ffmwa65Gc6Hn5LxvzmM8F1jzhsIUHgUZWlCiigG9MlwoXp_AqpPqdS_esmyzCsBivV7o10fxXgagLFbZDsxmb2COi44dzxRsBK-plDoBZSsoaXbuNPeU4941qWBBv0fKVEfOvud5yejh0NWdLr1U0LnMmts2eYhDMLsZgEHa3TV5aEXbEG-zZZnasiXfLMGnaScVeNKRHDiT1DNunRGF5pMFtUaAiCKe5h4hp84jHHks9mJ8mMjBRBOMrT9G45wommis84bjYThZHuPYwzA_xqeIHUU8UZjyYxDOiOIJwhj_uRKnzhOc3FHsdHgoiUNJJhRTfgzFGVEyoRijj0JZAwPYU9GTrtFjfDHbFVQt7WkFUx02RJzMMF21joyKFz-shqkSIw2g4OOxhemBnKXOxqEhiqKO6DHt_3YHwr44v-XXX7It6B4?type=png)](https://mermaid.live/edit#pako:eNqNkl1rgzAUhv9KyMXYwF74cSVjYA0rhY6WKRQWe5FqWqU1cUm8GKX_ffmwa65Gc6Hn5LxvzmM8F1jzhsIUHgUZWlCiigG9MlwoXp_AqpPqdS_esmyzCsBivV7o10fxXgagLFbZDsxmb2COi44dzxRsBK-plDoBZSsoaXbuNPeU4941qWBBv0fKVEfOvud5yejh0NWdLr1U0LnMmts2eYhDMLsZgEHa3TV5aEXbEG-zZZnasiXfLMGnaScVeNKRHDiT1DNunRGF5pMFtUaAiCKe5h4hp84jHHks9mJ8mMjBRBOMrT9G45wommis84bjYThZHuPYwzA_xqeIHUU8UZjyYxDOiOIJwhj_uRKnzhOc3FHsdHgoiUNJJhRTfgzFGVEyoRijj0JZAwPYU9GTrtFjfDHbFVQt7WkFUx02RJzMMF21joyKFz-shqkSIw2g4OOxhemBnKXOxqEhiqKO6DHt_3YHwr44v-XXX7It6B4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "o6U2hkPfjBAb",
        "outputId": "77dfbb3c-4da7-4d66-c057-36a5fc5a5e85"
      },
      "outputs": [],
      "source": [
        "def sequential_process_embeddings():\n",
        "    for idx, stock in company_tickers.items():\n",
        "        stock_ticker = stock['ticker']\n",
        "        stock_data = get_stock_info(stock_ticker)\n",
        "        stock_description = stock_data['Business Summary']\n",
        "\n",
        "        print(f\"Processing stock {idx} / {len(company_tickers)} :\", stock_ticker)\n",
        "\n",
        "        docs = Document(page_content=stock_description, metadata=stock_data)\n",
        "        print(docs)\n",
        "        vectorstore_from_documents = PineconeVectorStore.from_documents(\n",
        "            documents=[docs],\n",
        "            embedding=hf_embeddings,\n",
        "            index_name=index_name,\n",
        "            namespace=namespace\n",
        "        )\n",
        "    return \"Done\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Parallelizing Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmXAEa0vlTIj"
      },
      "source": [
        "[![](https://mermaid.ink/img/pako:eNqFk0uLgzAQgP_KkMOe7MHXRZaC1baXvsDCwqqHrGarVJMSE9hS-983NnWxULceRmf4Pp2MyQVlLCfIQweOTwXsw4SCuvw4Eiw7wqpsxPsXn_r-bmXAcrtdqts6WuwN2Ecr3wB__blJYTKZwixe45JCwKjgrKoI7zwXdphjlVXwwfiR8CbVH9BxdjPbqKxlJTAlTDbVuYXAjDUNZveSHWcZaRromkj_F61etIbire8Xpt2b9tDslvpCdHrRGYrddF6Ibi-6D4vsBjqcUWDe_NCMl0TAG6gfwwmEWOA7FlgasEYBWwP2KOBowBkFXA24Y4COoW61DRklLcwvQUHUHooEFrK53hHrAbkX7WdF51nRfVLUcX4fs8y6ObawMON-phvyI2CGRVakyEA14TUuc7XnL52ZIFGQmiTIU4855scEJfSqOCwFi840Q57gkhiIM3kokPeNq0Zl8pRjQcISq4NT_1VPmH4y1ufXXwdkCM8?type=png)](https://mermaid.live/edit#pako:eNqFk0uLgzAQgP_KkMOe7MHXRZaC1baXvsDCwqqHrGarVJMSE9hS-983NnWxULceRmf4Pp2MyQVlLCfIQweOTwXsw4SCuvw4Eiw7wqpsxPsXn_r-bmXAcrtdqts6WuwN2Ecr3wB__blJYTKZwixe45JCwKjgrKoI7zwXdphjlVXwwfiR8CbVH9BxdjPbqKxlJTAlTDbVuYXAjDUNZveSHWcZaRromkj_F61etIbire8Xpt2b9tDslvpCdHrRGYrddF6Ibi-6D4vsBjqcUWDe_NCMl0TAG6gfwwmEWOA7FlgasEYBWwP2KOBowBkFXA24Y4COoW61DRklLcwvQUHUHooEFrK53hHrAbkX7WdF51nRfVLUcX4fs8y6ObawMON-phvyI2CGRVakyEA14TUuc7XnL52ZIFGQmiTIU4855scEJfSqOCwFi840Q57gkhiIM3kokPeNq0Zl8pRjQcISq4NT_1VPmH4y1ufXXwdkCM8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 9037 successful tickers\n",
            "Loaded 1134 unsuccessful tickers\n"
          ]
        }
      ],
      "source": [
        "def refresh_tracking_lists():\n",
        "    # Initialize tracking lists\n",
        "    successful_tickers = []\n",
        "    unsuccessful_tickers = []\n",
        "\n",
        "    # Build tracking lists --Load existing successful/unsuccessful tickers\n",
        "    try:\n",
        "        with open('successful_tickers.txt', 'r') as f:\n",
        "            successful_tickers = [line.strip() for line in f if line.strip()]\n",
        "        print(f\"Loaded {len(successful_tickers)} successful tickers\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"No existing successful tickers file found\")\n",
        "\n",
        "    try:\n",
        "        with open('unsuccessful_tickers.txt', 'r') as f:\n",
        "            unsuccessful_tickers = [line.strip() for line in f if line.strip()]\n",
        "        print(f\"Loaded {len(unsuccessful_tickers)} unsuccessful tickers\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"No existing unsuccessful tickers file found\")\n",
        "    \n",
        "    return successful_tickers, unsuccessful_tickers\n",
        "\n",
        "successful_tickers, unsuccessful_tickers = refresh_tracking_lists()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_stock_pc(stock_ticker: str) -> str:\n",
        "    \"\"\"\n",
        "    Get a stock ticker info and store it in Pinecone.\n",
        "    Uses global variables (successful_tickers and unsuccessful_tickers) as tracking lists to guarantee ticker is processed only once.\n",
        "    \"\"\"\n",
        "\n",
        "    # Skip if already processed\n",
        "    if stock_ticker in successful_tickers:\n",
        "        return f\"Already processed {stock_ticker}\"\n",
        "\n",
        "    try:\n",
        "        # Get and store stock data\n",
        "        stock_data = get_stock_info(stock_ticker)\n",
        "        stock_description = stock_data['Business Summary']\n",
        "\n",
        "        # generate embeddings for one stock\n",
        "        stock_embedding = get_huggingface_embeddings(stock_description)\n",
        "\n",
        "        # insert the stock embedding into the Pinecone index\n",
        "        stock_embedding_list = stock_embedding.tolist() if isinstance(stock_embedding, np.ndarray) else stock_embedding\n",
        "\n",
        "        pc_index.upsert(vectors=[\n",
        "        {\"id\":str(stock_data[\"Ticker\"]), \"values\":stock_embedding_list, \"metadata\":stock_data}\n",
        "        ], namespace=namespace)\n",
        "\n",
        "        # Track success\n",
        "        with open('successful_tickers.txt', 'a') as f:\n",
        "            f.write(f\"{stock_ticker}\\n\")\n",
        "        successful_tickers.append(stock_ticker)\n",
        "\n",
        "        return f\"Processed {stock_ticker} successfully\"\n",
        "\n",
        "    except Exception as e:\n",
        "        # Track failure\n",
        "        with open('unsuccessful_tickers.txt', 'a') as f:\n",
        "            f.write(f\"{stock_ticker}\\n\")\n",
        "        unsuccessful_tickers.append(f\"{stock_ticker}: [Error] {e}\")\n",
        "\n",
        "        return f\"ERROR processing {stock_ticker}: {e}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mClWyH8HXD-z",
        "outputId": "7ccbb4aa-b59c-41c9-bd15-a1c623e2a611"
      },
      "outputs": [],
      "source": [
        "def process_stock(stock_ticker: str) -> str:\n",
        "    \"\"\"\n",
        "    Get a stock ticker info and store it in Pinecone.\n",
        "    Uses global variables (successful_tickers and unsuccessful_tickers) as tracking lists to guarantee ticker is processed only once.\n",
        "    \"\"\"\n",
        "\n",
        "    # Skip if already processed\n",
        "    if stock_ticker in successful_tickers:\n",
        "        return f\"Already processed {stock_ticker}\"\n",
        "\n",
        "    try:\n",
        "        # Get and store stock data\n",
        "        stock_data = get_stock_info(stock_ticker)\n",
        "        stock_description = stock_data['Business Summary']\n",
        "\n",
        "        # Store stock description in Pinecone\n",
        "        vectorstore_from_texts = PineconeVectorStore.from_documents(\n",
        "            documents=[Document(page_content=stock_description, metadata=stock_data)],\n",
        "            ids=[stock_ticker],\n",
        "            embedding=hf_embeddings,\n",
        "            index_name=index_name,\n",
        "            namespace=namespace\n",
        "        )\n",
        "\n",
        "        # Track success\n",
        "        with open('successful_tickers.txt', 'a') as f:\n",
        "            f.write(f\"{stock_ticker}\\n\")\n",
        "        successful_tickers.append(stock_ticker)\n",
        "\n",
        "        return f\"Processed {stock_ticker} successfully\"\n",
        "\n",
        "    except Exception as e:\n",
        "        # Track failure\n",
        "        with open('unsuccessful_tickers.txt', 'a') as f:\n",
        "            f.write(f\"{stock_ticker}\\n\")\n",
        "        unsuccessful_tickers.append(stock_ticker)\n",
        "\n",
        "        return f\"ERROR processing {stock_ticker}: {e}\"\n",
        "\n",
        "def parallel_process_stocks(tickers: list, max_workers: int = 10) -> None:\n",
        "    \"\"\"\n",
        "    Processes a list of stock tickers in parallel using a thread pool executor.\n",
        "    \"\"\"\n",
        "    # Module \"concurrent.futures\" is part of the standard library and provides a high-level interface for asynchronously executing callables (functions or methods) using threads or processes. (futures a like promises)\n",
        "\n",
        "    # - ThreadPoolExecutor: Manages a pool of threads to execute tasks concurrently.\n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "        # define an executor to run the process_stock function in each thread\n",
        "            # trigger independent threads with the \"submit\" method (build set of \"futures\")\n",
        "            # handle futures with the \"as_completed\" method\n",
        "        # here, we use a list comprehension to build a dictionary of futures\n",
        "            # list comprehension to build a dictionary from the tickers list\n",
        "            # \"submit\" method is provided by the ThreadPoolExecutor and schedules callable for when arguments are ready. It is optimized to schedule multiple calls at once.\n",
        "        future_to_ticker = {\n",
        "            executor.submit(process_stock_pc, ticker): ticker\n",
        "            for ticker in tickers\n",
        "        }\n",
        "        # - as_completed(): Returns an iterator over the futures in the order of completion.\n",
        "        # access local variable \"future_to_ticker\" to get the output of the callable function and check if there was an error\n",
        "        for future in concurrent.futures.as_completed(future_to_ticker):\n",
        "            ticker = future_to_ticker[future]\n",
        "            try:\n",
        "                # - result(): Retrieves the result of the callable associated with the future.\n",
        "                result = future.result()\n",
        "                print(result)\n",
        "\n",
        "                # Stop on error\n",
        "                if result.startswith(\"ERROR\"):\n",
        "                    print(f\"Stopping program due to error in {ticker}\")\n",
        "                    executor.shutdown(wait=False)\n",
        "                    raise SystemExit(1)\n",
        "\n",
        "            except Exception as exc:\n",
        "                print(f'{ticker} generated an exception: {exc}')\n",
        "                print(\"Stopping program due to exception\")\n",
        "                executor.shutdown(wait=False)\n",
        "                raise SystemExit(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REPORT\n",
            "Unique tickers: 9998\n",
            "Unique successful tickers: 9037\n",
            "Unique to process: 961\n"
          ]
        }
      ],
      "source": [
        "# Prepare your tickers: remove already processed + remove duplicates\n",
        "tickers_to_process = list(set([company_tickers[num]['ticker'] for num in company_tickers.keys() if company_tickers[num]['ticker'] not in successful_tickers]))\n",
        "\n",
        "# Report\n",
        "print(\"REPORT\")\n",
        "print(\"Unique tickers:\", len(set(company_tickers.keys())))\n",
        "print(\"Unique successful tickers:\", len(set(successful_tickers)))\n",
        "print(\"Unique to process:\", len(set(tickers_to_process)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Process them\n",
        "# parallel_process_stocks(tickers_to_process, max_workers=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Explore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Web Scrapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Crossbeam CEO and co-founder Bob Moore shares his tools for quashing biases in pursuit of the truth at every stage of company building.\n",
            "Founders are unrelenting optimists. It’s practically a requisite trait to start a company — you have to suspend disbelief to build toward the future state you’ve imagined.\n",
            "But if grit goes untempered by realism, blind spots can emerge. When you’ve put everything on the line to make your startup work, it’s easy for happy ears syndrome to set in, only taking in what you want to hear and subconsciously filtering out the rest.\n",
            "Three-time founder Bob Moore ran into this pitfall while building his first two startups, which, by his own account, netted good-not-great outcomes. In a postmortem, he could easily point to bad timing, market dynamics or fearsome competitors — in other words, things outside of his control. Instead, he calls out the limits of his own judgment as a young founder.\n",
            "Moore launched his first company, an analytics platform called RJMetrics, on the heels of the 2008 downturn. He and his co-founder muscled their way through a turbulent first few years, successfully bootstrapping the company and finding product-market fit.\n",
            "Then, the market moved, and they got left behind. RJMetrics still scored a modest acquisition in 2016, but competitor Looker far upstaged them with a $2.6 billion sale to Google. Moore’s second startup, Stitch, was a spinoff of RJMetrics’ data infrastructure tech and nabbed a heftier acquisition in less than two years — but it still wasn't the IPO-scale smash hit that he’d been hoping for.\n",
            "“If I had to distill the lesson down to something that I wish I had more of back then — and something I’ve worked on relentlessly since — is this idea of intellectual honesty. It’s something that all founders need to care really deeply about,” says Moore. For founders, intellectual honesty can be defined as an openness to — and active pursuit of — the truth, even when it proves you wrong. \n",
            "In this exclusive interview, Moore follows up on his treatise on startup resiliency with a founder’s guide to intellectual honesty, making this abstract concept actionable by laying out a set of tactics to get to the ground truth more quickly. He puts his strategies into context alongside his own experiences as a multi-time founder, offering up specific examples of the biases most beguiling to founders, and sharing how he’s combating them now as he tackles his third company, Crossbeam (a partnerships ecosystem platform he calls the “LinkedIn for data”).\n",
            "Moore starts by outlining several checks for the early days of company building. He then unpacks how to interpret product-market fit signals, from the warning signs he missed that RJMetrics was losing traction to the indicator he identified for Crossbeam. He wraps up with his takeaways from a growth-stage test of his intellectual honesty: deciding to merge with a competitor.\n",
            "Moore has had a decade-plus in the trenches to develop these psychological guardrails, which he’s now generously turned into the candid guide he wished he had when he was just starting out.\n",
            "For many founders, one of the first and most consequential decisions that can predate the startup idea itself is choosing someone to build with. When thinking through your dream co-founder criteria, Moore unsurprisingly recommends adding intellectual accountability to your list.\n",
            "This is one early call Moore thinks he got right when choosing a co-founder in Jake Stein, who gave Moore some of his most memorable lessons in intellectual honesty when they were building RJMetrics and Stitch together.\n",
            "He shares an example of how the duo balanced each other out. “Back in the early days of RJMetrics, I’d read whatever the hot startup book of the day was, and I went to Jake with all these ideas from the book and told him, ‘We should do this and this.’ And he said, ‘That’s cool. But what in that book did you not agree with?’” says Moore.\n",
            "“That took me aback. I hadn’t pushed myself to exist in a space where I could hold two thoughts at the same time — in this case, that this book might have both extremely good ideas and also bad advice that won’t work for us,” he says.\n",
            "Across a decade and two startups, this dynamic helped both Moore and Stein get good at looking at both sides of a problem. \n",
            "“Jake would sometimes call himself the Charlie Munger to my Warren Buffett. That's how it started out. But over the course of the decade, we converged into both being able to hold those two conflicting thoughts at once.”\n",
            "“The thing that my co-founder Jake brought to my thinking was helping me become not more pessimistic or critical, but capable of holding two conflicting thoughts in my head at the same time,” he says.\n",
            "In the six-month interim after selling Stitch, Moore attempted to take some time off and get some R&R. Except he couldn’t quit thinking about what he wanted to do next — so he dug up a running list of startup ideas he had tucked away in Evernote (“which would probably be in Notion now,” Moore notes).\n",
            "“I probably should have gone to therapy, but instead I cracked that list open. I tried to sit on a beach for a couple of weeks and just lost my mind,” he jokes.\n",
            "This third time around, Moore wanted to build something even bigger than his previous two startups. So he knew he’d have to take some time to mull over which idea had the most legs.\n",
            "First, he had to whittle down his list of roughly 100 miscellaneous entries — which ran the gamut from B2B SaaS tools to an escape room franchise.\n",
            "There’s a common startup refrain that encourages aspiring founders to “fall in love with the problem.” This isn’t bad advice, considering most founders will dedicate years of their life to solving it. But it misses another equally important dimension. Too often, founders — especially those earlier in their careers — fail to take their own strengths into account when choosing an idea, merely chasing market trends or their own passions.\n",
            "When Moore started RJMetrics, he and Stein were fresh off a two-year stint in venture capital, hungry for a startup of their own. But when they quit their investor day jobs to get RJMetrics off the ground, they didn’t have a strategic game plan beyond wanting in on the heating-up analytics market.\n",
            "“We went in as mercenaries. We wanted in on this startup game and big data was increasingly a thing. I knew how to write a damn good SQL query. But that was all we had,” says Moore.\n",
            "Looking back on it now, Moore thinks one of the contributing factors to RJMetrics’ shorter shelf-life was that the founding duo lacked a sense of where the market was headed. “When we started RJMetrics, I didn't have strong conviction. It may have been something that lit up my brain, but I didn’t even know the word ‘dashboard’ until after I started the company. We didn't know business intelligence as a market — we didn't even know who Gartner was,” he says.\n",
            "Years into building RJMetrics, this absence of a long-term vision became glaring in the product strategy. “We went out in that market and we hustled for the first couple years. But when we got stuck on a product direction, more often than not, we’d turn to the data and customer feedback and say, ‘Well, eight people asked for that, and six people asked for that. So we’ll just build the thing more people want,” he says. “Because we weren’t steering with a solid strategy, we pursued all these product micro-optimizations and landed ourselves in a place where we created a company that creates some value for some people. Our growth was stuck on a local maximum.”\n",
            "“RJMetrics became designed by committee. We didn’t have a core conviction that a certain specific thing ought to exist because that’s where the market was going. That wasn’t there,” says Moore.\n",
            "So when Moore was assessing ideas for his third startup, he knew he needed to be honest with himself about not only what he was excited to build, but what he was uniquely positioned to build well, given his chops as a multi-time SaaS founder.\n",
            "To do that, he devised a simple founder-market fit pre-screen — a mental matrix with two dimensions. He posed these questions to himself:\n",
            "This helped Moore quickly rule out the oddball ideas and pipe dreams. “This exercise took my list of 100 down to 10 or 15 ideas,” he says.\n",
            "“I had varying levels of where the ideas for my previous companies fell in the two-by-two matrix. I think that was part of why those businesses were base hits, and neither one of them got to an IPO scale,” says Moore.\n",
            "With the remaining handful of ideas that landed in the top right quadrant of his mental matrix, Moore wanted to get some outside opinions. But he chose to do things differently for the validation step: He bypassed the classic customer-driven discovery model and instead ran his remaining ideas past fellow founders.\n",
            "Moore felt that founders could offer more nuanced perspectives — and widen any preconceived notions he might have had about each of these ideas. “Founders are special. They need to develop an extremely high level of empathy and understanding for the needs of people across multiple personas, and also understand a baseline grasp on how markets evolve over time and what makes for something that's more durable and versatile,” he says.\n",
            "“Rather than narrowing these ideas down into the scope of how a persona would use it, I was able to broaden my horizons of what they could become,” says Moore. “I wasn't interested in having my next thing be anything other than an IPO-scale business — I wasn’t optimizing for a ‘build it for a few years and sell’ situation. I thought I had one more startup in me and I wanted to see how far I could take it.”\n",
            "But Moore was aware that with this method of idea validation, he ran the risk of confronting a bias. Founders, a famously optimistic bunch, default to seeing the potential in an idea — and in a fellow founder. So Moore knew a founder friend might still be willing to make a bet on him, even if they thought his idea was bad — and not offer up any constructive feedback.\n",
            "Moore admits he probably wouldn’t be fully honest if he were in the other founder’s shoes. “If a friend of mine who started and sold a company comes to me with a new idea, I figure they're already attached to this idea and I'm not going to talk them out of it,” he says. “Even if I don't love the idea, if I know this person well enough I actually might still write an angel check and make a bet on them — not because I think the idea is going to work, but because I think this person is not going to allow themselves to fail,” he says.\n",
            "“So the FOMO of not being in on their next thing is greater than my willingness to create confrontation with them, which isn’t a hard ratio to keep. I'm not going to give them as candid feedback as I should,” says Moore.\n",
            "When pitching his ideas to fellow founders, Moore built in a guard to fend off empty flattery: He told each founder to choose which of the three ideas they liked the best.\n",
            "“I started the meeting by not biasing them in any way. I’d say, ‘Hey, I've got three business ideas. I like them all equally. I want to pitch you on them and see where it goes.’ I did around 20 or 30 of these calls and I distributed the 10 ideas across all of them,” says Moore.\n",
            "This approach gave Moore much more revealing responses than, “I like that!” or, “That’s cool.” “I made these founders compare and contrast and ask, ‘Why this one? Why not that one?’ This created a forcing function to encourage them to criticize my ideas,” he explains.\n",
            "The idea for what would become Crossbeam quickly bubbled to the top. Moore knew it was a winner when founders started recommending who else he should talk to — essentially pointing him toward potential customers. The idea had a built-in viral loop.\n",
            "“With the Crossbeam idea, there was always a next step. People kept telling me, ‘You know who you should talk to about this? Because I know they’ve run into this problem.’ Or, ‘Can you put me on your mailing list so I get updates when you actually start building this thing?’ Coming out of the conversations where I talked about Crossbeam, I was actually cultivating a waitlist, some pent-up demand.”\n",
            "Moore knows all too well that the levels of product-market fit aren’t a one-way door.\n",
            "RJMetrics arrived early to the data market during a recession and started out with a slow drip of revenue. It later clicked into place and enjoyed a few years of up-and-to-the-right numbers. Then, big players like Amazon Redshift, Tableau and Looker shook up the data stack, and RJMetrics didn’t adjust the product — and lost its momentum.\n",
            "So he’s developed a clear eye for what’s a mirage and what’s real when it comes to assessing product-market fit. Here, Moore breaks down the corners he refused to see around at RJMetrics and the litmus test he used for Crossbeam.\n",
            "In hindsight, Moore recalls two omens that RJMetrics’ product-market fit was slipping away: a high churn rate, and new competition cropping up.\n",
            "But he didn’t identify these cues as warning signs at the time. He attributes his failure to recognize what was happening to a line of thinking that’s especially tempting to bullish founders: “We know better than they do.”\n",
            "Building RJMetrics in a volatile financial landscape meant that there was always some degree of instability with its customers. “We always had a problem with churn at RJMetrics. We had a fairly low entry-level price point, and there were a lot of companies going out of business and getting acquired. We used to call it ‘structural churn’ — a baseline 10% of all our business in any given year would just go away because the companies would go out of business,” says Moore.\n",
            "But once the modern data stack era rolled around by 2015, the churn was magnified. “All these things started to break at once, and one of them was that churn got a little bit worse. Another was that our outbound SDR program, which used to be super ROI positive, completely stopped working. The economics of it went upside down,” says Moore.\n",
            "At the time, he and the team brushed off the issue — chalking it up to their customers making bad decisions. “We had a bunch of customers that churned because they decided to go to Looker or because their engineering team was going to take over the analytics stack and the marketing team was losing control of that budget. Our consistent reaction to that was, ‘Oh, they’ll be back in a year,’” he says.\n",
            "“For the sake of pattern recognition, this happened enough times that at some point, it clicked and we realized, ‘Oh, wait, I think we're the dumb ones.’ This was a pattern that we should have picked up on earlier.”\n",
            "In retrospect, another clue that the data market was quickly moving away from RJMetrics’ product came from a TechCrunch reporter — but at the time, Moore dismissed the threat that growing competition posed, citing the reporter’s lack of knowledge about the market.\n",
            "“When we announced our Series B round, Amazon had just launched Redshift as a data warehouse product. It didn’t even register as something that was competitive. It was an infrastructure product selling to engineering teams to store data, and we were an analytics product selling to marketing teams,” says Moore. “But a TechCrunch reporter asked me this question: ‘Aren't you scared of Redshift?’”\n",
            "Moore didn’t flinch. “I was so adamant that these were two completely different worlds. I remember talking to Jake, thinking, ‘This reporter must be on the wrong beat. They're trying to make this a story about Amazon because it'll generate more clicks. They don’t understand how our business works,’” he says.\n",
            "In hindsight, of course, the reporter proved to be onto something. “They saw around a corner when I was refusing to.”\n",
            "Moore’s advice here for founders is to be wary of the tendency to think that you know better than the people in your ecosystem — from customers to investors to reporters.\n",
            "If you start getting increasingly skeptical about troublesome data trends or industry observations, take a step back and question whether you’re the one obscuring what’s really happening.\n",
            "Moore contrasts the cautionary tale of waning product-market fit at RJMetrics to the powerful early sign that he’d found it at Crossbeam.\n",
            "To sidestep the cold-start problem, B2B startups launching their products to market typically lean on warm intros and existing relationships for their first few customers. But there’s a downside to that approach: People you know aren’t always going to be honest with you about whether they actually want to use your product.\n",
            "“Let’s say I take my product to a friend who started another company. He doesn’t want to hurt my feelings, so he’ll pay 50 bucks a month just to make me go away and not have to have an awkward conversation.’ And the tool will sit around and never get used,” explains Moore.\n",
            "So Moore needed to be careful when gauging interest from his own network — because folks cutting a check alone was not a strong enough PMF signal. \n",
            "Crossbeam is a network-driven software business, which is an approach typically reserved for consumer social networks. The conceit of this growth model is that if all your friends are on a new social network, you’ll want to join too. \n",
            "But on the flip side, if none of your friends are on it, you wouldn’t be inclined to sign up — unless you’re willing to do the heavy lifting of recruiting them onto it. It wouldn’t make sense for a company to join the Crossbeam platform if none of its partners were on it.\n",
            "“With a product like Crossbeam, this person that you’re asking to take a chance on you isn’t just spending their own time and their own energy to do you a favor. They’re also expending their social capital,” Moore explains.\n",
            "This created a pressure test for product-market fit. In the realm of B2B SaaS buying, it’s one thing to write a check — it’s far more telling when people are willing to spend their own precious social capital.\n",
            "“So if this would have fallen flat, it would have fallen flat immediately. My bluff would have been called the second I said to one of our earliest customers, ‘Hey, I know you said you like this, but can you also invite Zendesk to the platform?’ That's a real ‘show your cards’ moment,” he says.\n",
            "“By the time we get more than one degree of separation away from me and my personal relationships, that virality has nothing to do with my relationships and everything to do with people being willing to spend social capital just to use the product.”\n",
            "Founders might bristle at the idea of joining forces with a competitor after years of going head-to-head in the market. But that’s exactly what Moore did at Crossbeam, which recently merged with Reveal.\n",
            "In Moore’s view, this was the ultimate test of his intellectual honesty — and a far more mature perspective on competition compared to the one he had back at RJMetrics.\n",
            "Moore shares the backstory for the unconventional decision for two scaling private companies to team up. “Within six months of me starting this company, another guy named Simon Bouchez, who’s a repeat founder based in Paris, started a company that would become Reveal, which was doing basically the exact same thing,” says Moore.\n",
            "It’d be understandable for Moore to suspect imitation, but he didn’t think that was the case. “I think we came up with the same idea at the same time because we observed the same things at the same moment. He was based in Europe, so they had collected a lot of business in Europe,” he says.\n",
            "Moore eventually met Bouchez at a partnership leadership event in Miami. The two didn’t even chat about their competing businesses. Instead, they realized how much they clicked. “​​Our stories, despite being theoretically archrivals out there on the market, were basically the same. He’s like the French version of me. I'm the Philly version of him.”\n",
            "But the idea to merge companies didn’t come from either Moore or Bouchez. It came from their customers. “I started to notice in our product feedback channel that the number one requested feature from Crossbeam was for us to integrate with Reveal and to support the companies that were on the Reveal network,” says Moore. “We'd host a webinar and people would put in the chat, “When is the Reveal integration coming?”\n",
            "“It got to a point where we knew we had to put egos aside and do what's right for the customer here. Neither one of us could realize the true potential of our business without coming together.” \n",
            "For Moore, it was a decision with roots all the way back to when he first started leafing through his digital notebook full of ideas for his third startup. After two middling exits, he was determined to make a much bigger splash — but to hang tight to his original goal of building an IPO-scale business, he needed to let go of his ego. \n",
            "“What was important to us was making this as big as we could possibly make it, and not having our particular company's name on the business card or going down in history as the one that won the big battle,” he says. “We were both willing to set aside some dilution, some pride and some sense of control to make this one cohesive thing that will actually create what we wanted to create for our customers in the first place.” \n",
            "This article is a lightly edited version of our podcast interview with Moore on In Depth. Listen to the full episode here.\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def get_content_from_url(url):\n",
        "    r = requests.get(url)\n",
        "    soup = BeautifulSoup(r.text, 'html.parser')\n",
        "    s = soup.find('div', class_='entry-content')\n",
        "    content = soup.find_all('p')\n",
        "    content = [p.text for p in content]\n",
        "    content = \"\\n\".join(content)\n",
        "    return content\n",
        "\n",
        "url = \"https://review.firstround.com/the-uncomfortable-truth-a-3x-founders-guide-to-intellectual-honesty/\"\n",
        "print(get_content_from_url(url))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LLMs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# process_stock_pc(\"MOND\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# EXECUTE CODE CREATED BY AN LLM\n",
        "\n",
        "from langchain_core.tools import Tool\n",
        "from langchain_experimental.utilities import PythonREPL\n",
        "\n",
        "python_repl = PythonREPL();\n",
        "\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"python_repl\",\n",
        "        description=\"A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`.\",\n",
        "        func=python_repl.run,\n",
        "    )\n",
        "]\n",
        "\n",
        "# tools can not output a value. It canonly be used to output prints in the console\n",
        "script_prompt = \"\"\"\n",
        "def funct():\n",
        "    import yfinance as yf\n",
        "    ticker = \"TSLA\"\n",
        "    stock = yf.Ticker(ticker)\n",
        "    return stock.info\n",
        "print(funct())\n",
        "\"\"\"\n",
        "\n",
        "# tools[0].run(script_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Yahoo Finance API\n",
        "\n",
        "Reference:\n",
        "* https://ranaroussi.github.io/yfinance/index.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'id': 'ARGUS_42037_TopBottomInsiderActivity_1733484442000',\n",
              "  'headHtml': 'Daily – Vickers Top Buyers & Sellers for 12/06/2024',\n",
              "  'provider': 'Argus Research',\n",
              "  'reportDate': '2024-12-06T11:27:22Z',\n",
              "  'reportTitle': 'The Vickers Top Buyers & Sellers is a daily report that identifies the five companies the largest insider purchase transactions based on the dollar value of the transactions as well as the five companies the largest insider sales transactions based on the dollar value of the transactions.',\n",
              "  'reportType': 'Top/Bottom Insider Activity'},\n",
              " {'id': 'ARGUS_42036_InsiderActivity_1733484442000',\n",
              "  'headHtml': 'Daily – Vickers Top Insider Picks for 12/06/2024',\n",
              "  'provider': 'Argus Research',\n",
              "  'reportDate': '2024-12-06T11:27:22Z',\n",
              "  'reportTitle': 'The Vickers Top Insider Picks is a daily report that utilizes a proprietary algorithm to identify 25 companies with compelling insider purchase histories based on transactions over the past three months.',\n",
              "  'reportType': 'Insider Activity'},\n",
              " {'id': 'MS_0P00009UPY_AnalystReport_1733478543000',\n",
              "  'headHtml': 'Analyst Report: Ulta Beauty, Inc.',\n",
              "  'provider': 'Morningstar',\n",
              "  'targetPrice': 360.0,\n",
              "  'targetPriceStatus': 'Maintained',\n",
              "  'investmentRating': 'Neutral',\n",
              "  'reportDate': '2024-12-06T09:49:03Z',\n",
              "  'reportTitle': 'With 1,385 stores at the end of fiscal 2023 and a partnership with Target, Ulta Beauty is the largest specialized beauty retailer in the US. The firm offers makeup (41% of 2023 sales), fragrances, skin care (19% of sales), and hair care products (19% of sales), and bath and body items. Ulta offers private-label products and more than 600 individual brands. It also offers salon services, including hair, makeup, skin, and brow services, in all stores. Most Ulta stores are approximately 10,000 square feet and are in suburban strip centers. Ulta was founded in 1990 and is based in Bolingbrook, Illinois. ',\n",
              "  'reportType': 'Analyst Report'},\n",
              " {'id': 'MS_0P00009C0X_AnalystReport_1733471523000',\n",
              "  'headHtml': 'Analyst Report: Lululemon Athletica Inc.',\n",
              "  'provider': 'Morningstar',\n",
              "  'targetPrice': 296.0,\n",
              "  'targetPriceStatus': 'Maintained',\n",
              "  'investmentRating': 'Neutral',\n",
              "  'reportDate': '2024-12-06T07:52:03Z',\n",
              "  'reportTitle': 'Lululemon Athletica designs, distributes, and markets athletic apparel, footwear, and accessories for women, men, and girls. Lululemon offers pants, shorts, tops, and jackets for both leisure and athletic activities such as yoga and running. The company also sells fitness accessories, such as bags, yoga mats, and equipment. Lululemon sells its products through more than 700 company-owned stores in about 20 countries, e-commerce, outlets, and wholesale accounts. The company was founded in 1998 and is based in Vancouver, Canada. ',\n",
              "  'reportType': 'Analyst Report'}]"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ticker = \"TSLA\"\n",
        "stock = yf.Ticker(ticker)\n",
        "\n",
        "# # General info\n",
        "# stock.info['sectorKey'] # stock.info['sector'].lower().replace(\" \", \"-\")\n",
        "# stock.info['industryKey'] # stock.info['industry'].lower().replace(\" \", \"-\")\n",
        "\n",
        "# # Sector\n",
        "# yf.Sector(stock.info['sectorKey']).industries.sort_values(by='key', ascending=True)\n",
        "# yf.Sector(stock.info['sectorKey']).top_companies\n",
        "yf.Sector(stock.info['sectorKey']).research_reports\n",
        "\n",
        "# # Industry\n",
        "# yf.Industry(stock.info['industryKey']).research_reports\n",
        "\n",
        "# # SEC Filings\n",
        "# stock.get_sec_filings()\n",
        "# # Basic Stock Information\n",
        "# get_stock_info(ticker)\n",
        "# # Stock History\n",
        "# stock.history(period=\"5d\")\n",
        "# # Stock Financials\n",
        "# stock.financials\n",
        "# # Stock Earnings (income statement)\n",
        "# stock.income_stmt\n",
        "# # Stock Cash Flow (cash flow statement)\n",
        "# stock.cashflow\n",
        "# # Stock Balance Sheet (balance sheet)\n",
        "# stock.balance_sheet\n",
        "# # Stock Market Capitalization\n",
        "# stock.info['marketCap']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HK_GCUV1OvIW"
      },
      "source": [
        "# Perform RAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 213,
      "metadata": {
        "id": "YkzNzCTdOrO5"
      },
      "outputs": [],
      "source": [
        "query = \"What are the best content streaming company?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Qualify user query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 215,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'$and': [{'Market Cap': {'$gt': 100000}}]}\n",
            "305 184 \"Global content streaming services with on-demand movies, TV shows, original series, and documentaries, emphasizing companies with large subscription bases and strategic partnerships.\"\n"
          ]
        }
      ],
      "source": [
        "# build prompt\n",
        "prompt = f\"\"\"\n",
        "You are a financial analyst, helping a client find stocks that are relevant to them and that generate good returns as an invetment opportunity. You will be given a raw query and your job is to qualify this query, adding context and keywords that will help delineate the user's interest and help you find the most relevant stocks.\n",
        "If the user expresses a preference, e.g. location, industry, political affiliation, branding positioning, etc, add that to the query.\n",
        "Your final output will be used to query the business summary of the stocks.\n",
        "Keep your output short and concise, conversational, but detailed with the context and keywords added. Do not include any additional text other than the qualified query.\n",
        "Finally, do not include any requirement that the company be publicly traded.\n",
        "\n",
        "Examples:\n",
        "\n",
        "$$Raw query$$ \"What are some companies that manufacture consumer hardware?\"\n",
        "$$Qualified query$$ \"Consumer-facing tech companies specializing in hardware development such as smartphones, laptops, smart home devices, gaming consoles, and VR headsets, listed on major US stock exchanges. Focus on companies with popular consumer brands and significant market presence.\"\n",
        "\n",
        "$$Raw query$$ \"What are some companies that sell home decor?\"\n",
        "$$Qualified query$$ \"Retailers specializing in home furniture, furnishings, and decorative items, such as furniture stores, home goods stores, and online home decor marketplaces, with a strong e-commerce presence. Focus on companies offering a wide range of products, including home textiles, kitchenware, and wall decor.\"\n",
        "\"\"\"\n",
        "\n",
        "prompt_prompter = f\"\"\"\n",
        "You were hired to write a query for a financial analyst. Your query will be used to match stocks with a similarity search. It must be short and conciese and dense with relevant keywords. Keep it at 2 sentences max. You will be given a raw query and your job is to write a short query that keeps the essence of the raw query.\n",
        "Your output must be only the requested query. No additional text.\n",
        "\"\"\"\n",
        "\n",
        "# get qualified query\n",
        "client = OpenAI(\n",
        "  base_url=\"https://api.groq.com/openai/v1\",\n",
        "  api_key=os.getenv(\"GROQ_API_KEY\")\n",
        ")\n",
        "\n",
        "llm_response_long = client.chat.completions.create(\n",
        "    model=\"llama-3.1-70b-versatile\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": prompt},\n",
        "        {\"role\": \"user\", \"content\": f\"Raw query: {query}\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "query_long = llm_response_long.choices[0].message.content\n",
        "\n",
        "llm_response_qualified = client.chat.completions.create(\n",
        "    model=\"llama-3.1-70b-versatile\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": prompt_prompter},\n",
        "        {\"role\": \"user\", \"content\": f\"Raw query: {query_long}\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "query_qualified = llm_response_qualified.choices[0].message.content\n",
        "\n",
        "# check if the qualified query uses special filters: Country, Sector, Market Cap, Volume\n",
        "\n",
        "filter_options_example = '''{\"$and\": [\n",
        "  {\"Market Cap\": {\"$gt\": 1000}},\n",
        "  {\"10-Day AVG Volume\": {\"$gte\": 1000000}}\n",
        "]}'''\n",
        "\n",
        "example_for = '{\"$and\": [{\"genre\": {\"$eq\": \"drama\"}}, {\"year\": {\"$gte\": 2020}}]}'\n",
        "example_or = '{\"$or\": [{\"genre\": {\"$eq\": \"drama\"}}, {\"year\": {\"$gte\": 2020}}]}'\n",
        "\n",
        "filter_prompt = f\"\"\"\n",
        "Check this query and assess if the answer to it requires any special filters. There are 2 filter options are: 'Market Cap' and '10-Day AVG Volume'.\n",
        "If the answer requires any of these filters, return the filter options in a dictionary with the filter name as key and the required value assigned to it. Do not include any other key different than those 2.\n",
        "Your output must be only the dictionary of filters, in JSON format. No additional text.\n",
        "\n",
        "Use any of the following operators:\n",
        "Filter\tDescription\tSupported types\n",
        "$eq:    Matches vectors with metadata values that are equal to a specified value.\tNumber, string, boolean\n",
        "$ne:\tMatches vectors with metadata values that are not equal to a specified value.\tNumber, string, boolean\n",
        "$gt:\tMatches vectors with metadata values that are greater than a specified value.\tNumber\n",
        "$gte:\tMatches vectors with metadata values that are greater than or equal to a specified value.\tNumber\n",
        "$lt:\tMatches vectors with metadata values that are less than a specified value.\tNumber\n",
        "$lte:\tMatches vectors with metadata values that are less than or equal to a specified value.\tNumber\n",
        "$in:\tMatches vectors with metadata values that are in a specified array.\tString, number\n",
        "$nin:\tMatches vectors with metadata values that are not in a specified array.\tString, number\n",
        "$exists:\tMatches vectors with the specified metadata field.\tBoolean\n",
        "\n",
        "Or combine operators:\n",
        "Operator\tExample\n",
        "$and\t    {example_for}\n",
        "$or         {example_or}\n",
        "\n",
        "Examples: {filter_options_example}\n",
        "\"\"\"\n",
        "\n",
        "filters = client.chat.completions.create(\n",
        "    model=\"llama-3.1-70b-versatile\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": filter_prompt},\n",
        "        {\"role\": \"user\", \"content\": f\"Query: {query_qualified}\"}\n",
        "    ],\n",
        ")\n",
        "\n",
        "filter_options = json.loads(filters.choices[0].message.content)\n",
        "print(filter_options)\n",
        "\n",
        "print(len(query_long), len(query_qualified), query_qualified)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get relevant stocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 216,
      "metadata": {},
      "outputs": [],
      "source": [
        "query = query_qualified"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get relevant data about the stocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 217,
      "metadata": {
        "id": "c2fO8ql_OrWs"
      },
      "outputs": [],
      "source": [
        "raw_query_embedding = get_huggingface_embeddings(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 218,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'$and': [{'Market Cap': {'$gt': 100000}}]}"
            ]
          },
          "execution_count": 218,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "filter_options"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 219,
      "metadata": {
        "id": "nM2LkWyXPAiX"
      },
      "outputs": [],
      "source": [
        "top_matches = pc_index.query(\n",
        "  vector=raw_query_embedding.tolist(),\n",
        "  top_k=5,\n",
        "  include_metadata=True,\n",
        "  namespace=namespace,\n",
        "  filter=filter_options\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 220,
      "metadata": {
        "id": "_U45gYqHPFdy"
      },
      "outputs": [],
      "source": [
        "contexts = [item['metadata']['Business Summary'] for item in top_matches['matches']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 221,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SeaChange International, Inc. provides video delivery, advertising, streaming platforms, and emerging Free Ad-Supported Streaming TV (FAST) products and services that facilitate the aggregation, licensing, management and distribution of video and advertising content worldwide. It offers Operator TV Platform solutions including customer's current network with OTT video management solutions in a single deployment, digital video broadcasting - cable / quadrature amplitude modulation networks with OTT streaming, and immersive multiscreen experience and on demand services, as well as pre-integrated solutions, such as multi-content delivery networks including Broadpeak, Edgeware and HBO, multidigital rights management, and seamless integration with existing network components. The company also provides StreamVid, a cloud-based OTT video platform for operators and content owners that enables streaming services, including content ingestion, workflow automation, user management, content protection, billing and entitlement, and user applications for various device platforms, such as mobile devices or Smart TVs; Advanced advertising, a unified ad tech solution to insert adverts into various video feeds, including broadcast, internet protocol television, and OTT; and Xstream platform, a cloud-based content monetization platform that provides the range of capabilities, including generation and distribution of FAST channels, streaming enablement via content aggregation, and targeted insertion of advertisement from various demand sources. In addition, it provides professional, and maintenance and technical support services, as well as managed services. The company sells and markets its products and services through a direct sales process, as well as to systems integrators and value-added resellers. It serves cable system operators, telecommunications companies, and satellite operators, as well as broadcasters and other content providers. The company was incorporated in 1993 and is headquartered in Boston, Massachusetts.\n",
            "\n",
            "-------\n",
            "\n",
            "Brightcove Inc. provides cloud-based streaming services the Americas, Europe, the Asia Pacific, Japan, India, and the Middle East. It offers Video Cloud, an online video streaming platform that enables its customers to publish, deliver, and distribute high-quality video to internet-connected devices. The company's solutions and products comprise Brightcove Marketing Studio, a video streaming solution; Brightcove Communications Studio for marketers and corporate communications professionals; Brightcove Media Studio, a solution for over-the-top (OTT) video services, media publishers, and leading broadcasters to monetize their media, live stream at scale, and nurture their audience lifecycle; Brightcove Audience Insights, a customer data platform for video streaming businesses; Zencoder, a cloud-based video encoding service; and Brightcove Beacon, a platform that enables its customers to launch premium OTT video streaming experiences, as well as Brightcove Marketplace. It also provides ad monetization; professional; customer success, support, and documentation; online and onsite training; and video.js and developer solutions. The company serves media companies, broadcasters, digital publishers, sports and entertainment companies, fashion and hospitality brands, faith-based institutions, retail and e-commerce businesses, and technology organizations, as well as government agencies, educational institutions, and non-profit organizations. Brightcove Inc. was incorporated in 2004 and is headquartered in Boston, Massachusetts.\n",
            "\n",
            "-------\n",
            "\n",
            "Liberty Global Ltd., together with its subsidiaries, provides broadband internet, video, fixed-line telephony, and mobile communications services to residential and business customers. It offers value-added broadband services, such as WiFi features, security, anti-virus, firewall, spam protection, smart home services, online storage solutions, and web spaces; and Connect Box that delivers in-home Wi-Fi service. The company provides various tiers of digital video programming and audio services, as well as digital video recorders and multimedia home gateway systems; Horizon 5, a cloud-based, multi-screen entertainment platform that combines linear television, including recording and replay features and video-on-demand services; Horizon Go, an online mobile app; and channels, including general entertainment, sports, movies, series, documentaries, lifestyles, news, adult, children, and ethnic and foreign channels. In addition, it offers postpaid and prepaid mobile services; circuit-switched telephony services; and personal call manager, unified messaging, and a second or third phone line at an incremental cost. Further, the company offers business services comprising voice, advanced data, video, wireless, cloud-based services, and mobile and converged fixed-mobile services to small or home offices, small businesses, and medium and large enterprises, as well as on a wholesale basis to other operators. It operates in Belgium, Switzerland, Ireland, Slovakia, and internationally. Liberty Global Ltd. was founded in 2004 and is based in Hamilton, Bermuda.\n",
            "\n",
            "-------\n",
            "\n",
            "Liberty Global Ltd., together with its subsidiaries, provides broadband internet, video, fixed-line telephony, and mobile communications services to residential and business customers. It offers value-added broadband services, such as WiFi features, security, anti-virus, firewall, spam protection, smart home services, online storage solutions, and web spaces; and Connect Box that delivers in-home Wi-Fi service. The company provides various tiers of digital video programming and audio services, as well as digital video recorders and multimedia home gateway systems; Horizon 5, a cloud-based, multi-screen entertainment platform that combines linear television, including recording and replay features and video-on-demand services; Horizon Go, an online mobile app; and channels, including general entertainment, sports, movies, series, documentaries, lifestyles, news, adult, children, and ethnic and foreign channels. In addition, it offers postpaid and prepaid mobile services; circuit-switched telephony services; and personal call manager, unified messaging, and a second or third phone line at an incremental cost. Further, the company offers business services comprising voice, advanced data, video, wireless, cloud-based services, and mobile and converged fixed-mobile services to small or home offices, small businesses, and medium and large enterprises, as well as on a wholesale basis to other operators. It operates in Belgium, Switzerland, Ireland, Slovakia, and internationally. Liberty Global Ltd. was founded in 2004 and is based in Hamilton, Bermuda.\n",
            "\n",
            "-------\n",
            "\n",
            "Liberty Global Ltd., together with its subsidiaries, provides broadband internet, video, fixed-line telephony, and mobile communications services to residential and business customers. It offers value-added broadband services, such as WiFi features, security, anti-virus, firewall, spam protection, smart home services, online storage solutions, and web spaces; and Connect Box that delivers in-home Wi-Fi service. The company provides various tiers of digital video programming and audio services, as well as digital video recorders and multimedia home gateway systems; Horizon 5, a cloud-based, multi-screen entertainment platform that combines linear television, including recording and replay features and video-on-demand services; Horizon Go, an online mobile app; and channels, including general entertainment, sports, movies, series, documentaries, lifestyles, news, adult, children, and ethnic and foreign channels. In addition, it offers postpaid and prepaid mobile services; circuit-switched telephony services; and personal call manager, unified messaging, and a second or third phone line at an incremental cost. Further, the company offers business services comprising voice, advanced data, video, wireless, cloud-based services, and mobile and converged fixed-mobile services to small or home offices, small businesses, and medium and large enterprises, as well as on a wholesale basis to other operators. It operates in Belgium, Switzerland, Ireland, Slovakia, and internationally. Liberty Global Ltd. was founded in 2004 and is based in Hamilton, Bermuda.\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\\n-------\\n\\n\".join(contexts))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "eE1T_TAOPGAH"
      },
      "outputs": [],
      "source": [
        "augmented_query = \"<CONTEXT>\\n\" + \"\\n\\n-------\\n\\n\".join(contexts[ : 10]) + \"\\n-------\\n</CONTEXT>\\n\\n\\n\\nMY QUESTION:\\n\" + query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "filter_options"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAnqmUbvPGCt",
        "outputId": "9245f795-d17a-4de4-f4c3-fcbf34d54da7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<CONTEXT>\n",
            "Code Green Apparel Corp. designs, manufactures, and distributes apparel products from eco-friendly and sustainable recycled textiles worldwide. It offers uniforms, caps, T-shirts, aprons, polo shirts, hats, pants, shorts, jackets, and accessories. The company was formerly known as J.D. Hutt Corporation and changed its name to Code Green Apparel Corp. in May 2015. Code Green Apparel Corp. was founded in 2007 and is based in Laguna Beach, California.\n",
            "\n",
            "-------\n",
            "\n",
            "Unifi, Inc., together with its subsidiaries, engages in the manufacture and sale of recycled and synthetic products in North America, Central America, South America, Asia, and Europe. Its polyester products include partially oriented yarn, textured, solution and package dyed, twisted, beamed, and draw wound yarns in virgin or recycled varieties; and nylon products comprise virgin or recycled textured, solution dyed, and spandex covered yarns. The company also provides recycled solutions made from pre-consumer and post-consumer waste, such as plastic bottle flakes, polyester polymer beads, and staple fiber. It offers recycled and synthetic products primarily to yarn manufacturers, knitters, and weavers that produces yarn and fabric for the apparel, hosiery, automotive, home furnishings, industrial, medical, and other end-use markets. The company sells its products through sales force and independent sales agents under the REPREVE brand. Unifi, Inc. was incorporated in 1969 and is headquartered in Greensboro, North Carolina.\n",
            "\n",
            "-------\n",
            "\n",
            "Sustainable Green Team, Ltd., through its subsidiaries, provides environmentally conscious solutions to residential, commercial, and government customers in the United States. It provides tree maintenance, disaster recovery, debris removal, disposal, arbor care, tree trimming, and storm debris clean-up services. The company also manufactures and sells mulch, lumber, and soil products under the Nature's Reflections brand name, as well as mulch colorants and coloring equipment under the Cheetah brand name. It serves retailers, wholesalers, landscapers, and garden centers. Sustainable Green Team, Ltd. was founded in 1997 and is based in Astatula, Florida.\n",
            "\n",
            "-------\n",
            "\n",
            "Rayonier Advanced Materials Inc. manufactures and sells cellulose specialty products in the United States, China, Latin America, Canada, Japan, Europe, Latin America, other Asian countries, and internationally. It operates through High Purity Cellulose, Paperboard, and High-Yield Pulp segments. The company's products include cellulose specialties, which are natural polymers that are used as raw materials to manufacture a range of consumer-oriented products, such as liquid crystal displays, impact-resistant plastics, thickeners for food products, pharmaceuticals, cosmetics, cigarette filters, high-tenacity rayon yarn for tires and industrial hoses, food casings, paints, and lacquers. It also offers commodity products, such as commodity viscose pulp used in woven applications, including rayon textiles for clothing and other fabrics, as well as in non-woven applications comprising baby wipes, cosmetic and personal wipes, industrial wipes, and mattress ticking; and absorbent materials consisting of fluff fibers that are used as an absorbent medium in disposable baby diapers, feminine hygiene products, incontinence pads, convalescent bed pads, industrial towels and wipes, and non-woven fabrics. In addition, the company provides paperboards for packaging, printing documents, brochures, promotional materials, paperback books and catalog covers, file folders, tags, and lottery tickets; and high-yield pulps to produces hardwood aspen, maple, and birch species for paperboard, packaging, printing and writing papers, and various other paper products. The company was founded in 1926 and is headquartered in Jacksonville, Florida.\n",
            "\n",
            "-------\n",
            "\n",
            "V.F. Corporation, together with its subsidiaries, engages in the design, procurement, marketing, and distribution of branded lifestyle apparel, footwear, and accessories for men, women, and children in the Americas, Europe, and the Asia-Pacific. It operates through three segments: Outdoor, Active, and Work. The company offers High performance outdoor apparel, footwear, equipment, accessories; outdoor, adventure-inspired lifestyle footwear, apparel, and accessories; performance merino wool and other natural fibers-based apparel and accessories; performance-based footwear; and high performance apparel and accessories based on natural fibers under the The North Face, Timberland, Smartwool, Icebreaker, and Altra brands. It also offers youth culture/action sports-inspired and streetwear apparel, footwear, and accessories; handbags, luggage, backpacks, totes, and accessories; outdoor-inspired apparel, footwear, and accessories; and backpacks and luggage under the Vans, Supreme, Kipling, Napapijri, Eastpak, and JanSport brands. In addition, the company provides work and work-inspired lifestyle apparel and footwear; and protective work footwear under the Dickies, and Timberland PRO brands. The company sells its products primarily to specialty stores, department stores, national chains, independently-operated partnership stores, and mass merchants, as well as sells through direct-to-consumer operations, including retail stores, concession retail stores, and e-commerce sites, and other digital platforms. V.F. Corporation was founded in 1899 and is headquartered in Denver, Colorado.\n",
            "-------\n",
            "</CONTEXT>\n",
            "\n",
            "\n",
            "\n",
            "MY QUESTION:\n",
            "South American apparel companies prioritizing eco-friendly materials like organic cotton, recycled polyester, and Tencel, with fair labor practices and certifications like B Corp or Fair Trade. Strong online presence and collaborations with sustainable suppliers desired.\n"
          ]
        }
      ],
      "source": [
        "print(augmented_query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "BcnhtcGpP42e"
      },
      "outputs": [],
      "source": [
        "client = OpenAI(\n",
        "  base_url=\"https://api.groq.com/openai/v1\",\n",
        "  api_key=os.getenv(\"GROQ_API_KEY\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "j_-UvIOmPGFA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Considering your request for companies in South America specializing in sustainable women's fashion made from eco-friendly materials, I've identified a few companies that fit your criteria. While there are not many South American companies in the provided context that specialize in both sustainable women's fashion and environmentally responsible manufacturing, I've found one company that meets some aspects of your request:\n",
            "\n",
            "1. Unifi, Inc. - Although not exclusively a South American company, Unifi, Inc. has a presence in South America. They offer a range of sustainable products, including REPREVE, a brand of recycled polyester yarn made from plastic bottle waste. Their polyester products are used to make apparel, including clothing made from sustainable materials.\n",
            "\n",
            "If I expand my search to companies that prioritize environmentally responsible manufacturing and fair labor practices, but are not necessarily based in South America or using eco-friendly materials like organic cotton, I can provide you with a list of companies that might fit your values:\n",
            "\n",
            "1. Code Green Apparel Corp. - While not based in South America, they design, manufacture, and distribute apparel products from eco-friendly and sustainable recycled textiles.\n",
            "2. V.F. Corporation - As mentioned earlier, V.F. Corporation owns various brands that prioritize sustainability. Some of their brands, such as The North Face, offer sustainable and environmentally responsible products.\n",
            "3. Lands' End, Inc. - Lands' End offers sustainable products and prioritizes environmentally responsible practices.\n",
            "\n",
            "It's worth noting that Unifi, Inc. has operations across the Americas, including South America, and has a large market cap among the companies in the provided context.\n"
          ]
        }
      ],
      "source": [
        "system_prompt = f\"\"\"You are an expert at providing answers about stocks. Please answer the question provided, in a conversational tone, but keep it professional and sharp. Assume the context in the prompt is part of your knowledge base, not something provided to you. Whenever you are asked to provide a list of companies, look for the companies with the highest market cap, within the prompt provided.\n",
        "\"\"\"\n",
        "\n",
        "llm_response = client.chat.completions.create(\n",
        "    model=\"llama-3.1-70b-versatile\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": augmented_query}\n",
        "    ]\n",
        ")\n",
        "\n",
        "response = llm_response.choices[0].message.content\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
